{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge and Lasso\n",
    "At this point we've seen a number of criteria and algorithms for fitting regression models to data. We've seen the simple linear regression using ordinary least squares, and its more general regression of polynomial functions. We've also seen how we can arbitrarily overfit models to data using kernel methods or feature engineering. With all of that, we began to explore other tools to analyze this general problem of overfitting versus underfitting. This included train and test splits, bias and variance, and cross validation.\n",
    "\n",
    "Now we're going to take a look at another way to tune our models. These methods all modify our mean squared error function that we were optimizing against. The modifications will add a penalty for large coefficient weights in our resulting model. If we think back to our case of feature engineering, we can see how this penalty will help combat our ability to create more accurate models by simply adding additional features.\n",
    "\n",
    "In general, all of these penalties are known as $L^p norms$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $L^p$ norm of x\n",
    "In order to help account for underfitting and overfitting, we often use what are called $L^p$ norms.   \n",
    "The **$L^p$ norm of x** is defined as:  \n",
    "\n",
    "### $||x||_p  =  \\big(\\sum_{i} x_i^p\\big)^\\frac{1}{p}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ridge (L2)\n",
    "One common normalization is called Ridge Regression and uses the $l_2$ norm (also known as the Euclidean norm) as defined above.   \n",
    "The ridge coefficients minimize a penalized residual sum of squares:    \n",
    "    $ \\sum(\\hat{y}-y)^2 + \\lambda\\bullet w^2$\n",
    "\n",
    "Write this loss function for performing ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_loss(y, y_hat, coeff_weights, lam = 0.8):\n",
    "    rss = np.sum((y_hat-y)**2)\n",
    "    norm = np.sum(lam * coeff_weights**2)\n",
    "    l2_err = rss + lam*norm\n",
    "    return l2_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lasso (L1)\n",
    "Another common normalization is called Lasso Regression and uses the $l_1$ norm.   \n",
    "The ridge coefficients minimize a penalized residual sum of squares:    \n",
    "    $ \\sum(\\hat{y}-y)^2 + \\lambda\\bullet |w|$\n",
    "\n",
    "Write this loss function for performing ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_loss(y, y_hat, coeff_weights, lam = 0.8):\n",
    "    rss = np.sum((y_hat-y)**2)\n",
    "    norm = np.sum(lam * np.abs(coeff_weights))\n",
    "    l1_err = rss + lam*norm\n",
    "    return l1_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run + Compare your Results\n",
    "Run a ridge lasso and unpenalized regressions on the dataset below.\n",
    "While we have practice writing the precursors to a full ridge regression, we'll import the package for now.\n",
    "Then, answer the following questions:\n",
    "* Which model do you think created better results overall? \n",
    "* Comment on the differences between the coefficients of the resulting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>domgross</th>\n",
       "      <th>title</th>\n",
       "      <th>Response_Json</th>\n",
       "      <th>Year</th>\n",
       "      <th>imdbRating</th>\n",
       "      <th>Metascore</th>\n",
       "      <th>imdbVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13000000</td>\n",
       "      <td>25682380</td>\n",
       "      <td>21 &amp;amp; Over</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>6.8</td>\n",
       "      <td>48</td>\n",
       "      <td>206513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45658735</td>\n",
       "      <td>13414714</td>\n",
       "      <td>Dredd 3D</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000000</td>\n",
       "      <td>53107035</td>\n",
       "      <td>12 Years a Slave</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>8.1</td>\n",
       "      <td>96</td>\n",
       "      <td>537525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61000000</td>\n",
       "      <td>75612460</td>\n",
       "      <td>2 Guns</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>6.7</td>\n",
       "      <td>55</td>\n",
       "      <td>173726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40000000</td>\n",
       "      <td>95020213</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>7.5</td>\n",
       "      <td>62</td>\n",
       "      <td>74170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     budget  domgross             title  Response_Json  Year  imdbRating  \\\n",
       "0  13000000  25682380     21 &amp; Over              0  2008         6.8   \n",
       "1  45658735  13414714          Dredd 3D              0  2012         0.0   \n",
       "2  20000000  53107035  12 Years a Slave              0  2013         8.1   \n",
       "3  61000000  75612460            2 Guns              0  2013         6.7   \n",
       "4  40000000  95020213                42              0  2013         7.5   \n",
       "\n",
       "   Metascore  imdbVotes  \n",
       "0         48     206513  \n",
       "1          0          0  \n",
       "2         96     537525  \n",
       "3         55     173726  \n",
       "4         62      74170  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('movie_data_detailed.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['budget', 'imdbRating',\n",
    "       'Metascore', 'imdbVotes']]\n",
    "y = df['domgross']\n",
    "\n",
    "def norm(col):\n",
    "    minimum = col.min()\n",
    "    maximum = col.max()\n",
    "    return (col-maximum)/(maximum-minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error  Ridge Model 1.0705617558826253e+17\n",
      "Test Error Ridge Model 6.095781681848846e+16\n",
      "\n",
      "\n",
      "Train Error Lasso Model 1.0705355940224341e+17\n",
      "Test Error Lasso Model 6.105577956427409e+16\n",
      "\n",
      "\n",
      "Train Error Unpenalized Linear Model 1.0705355940224341e+17\n",
      "Test Error Unpenalized  Linear Model 6.1055779723063096e+16\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Perform test train spli\n",
    "X_train , X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "ridge_reg = Ridge()\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "\n",
    "lasso_reg = Lasso()\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "def rss(residual_col):\n",
    "    return sum(residual_col.astype(float).map(lambda x: x**2))\n",
    "\n",
    "print('Train Error  Ridge Model', rss(y_train - ridge_reg.predict(X_train)))\n",
    "print('Test Error Ridge Model', rss(y_test - ridge_reg.predict(X_test)))\n",
    "print('\\n')\n",
    "\n",
    "print('Train Error Lasso Model', rss(y_train - lasso_reg.predict(X_train)))\n",
    "print('Test Error Lasso Model', rss(y_test - lasso_reg.predict(X_test)))\n",
    "print('\\n')\n",
    "\n",
    "print('Train Error Unpenalized Linear Model', rss(y_train - lin_reg.predict(X_train)))\n",
    "print('Test Error Unpenalized  Linear Model', rss(y_test - lin_reg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For this dataset there was little difference between the models. Ridge has every so slightly better test performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Altering Alpha\n",
    "\n",
    "Remember that we can also change our normalization coefficient, alpha, to adjust the strenght of our normalization.\n",
    "Iterate over the set **np.linspace(start=0.1, stop=2.5, num=13)** in order to find an optimal alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Ridge Test RSS: 6.081818824821337e+16, Best alpha: 2.5\n",
      "Minimum Lasso Test RSS: 6.105577932632072e+16, Best alpha: 2.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "min_test_error_ridge = []\n",
    "min_test_error_lasso = []\n",
    "optimal_ridge_alpha = 0\n",
    "optimal_lasso_alpha = 0\n",
    "for iter, a in enumerate(np.linspace(start=0.1, stop=2.5, num=13)):\n",
    "    ridge_reg = Ridge(alpha=a)\n",
    "    ridge_reg.fit(X_train, y_train)\n",
    "\n",
    "    lasso_reg = Lasso(alpha=a)\n",
    "    lasso_reg.fit(X_train, y_train)\n",
    "\n",
    "    ridge_train_rss = rss(y_train - ridge_reg.predict(X_train))\n",
    "    ridge_test_rss = rss(y_test - ridge_reg.predict(X_test))\n",
    "#     print('Train Error  Ridge Model', ridge_train_rss)\n",
    "#     print('Test Error Ridge Model', ridge_test_rss)\n",
    "#     print('\\n')\n",
    "    \n",
    "    lasso_train_rss = rss(y_train - lasso_reg.predict(X_train))\n",
    "    lasso_test_rss = rss(y_test - lasso_reg.predict(X_test))\n",
    "#     print('Train Error Lasso Model', lasso_train_rss)\n",
    "#     print('Test Error Lasso Model', lasso_test_rss)\n",
    "#     print('\\n')\n",
    "    \n",
    "    if iter == 0:\n",
    "        min_test_error_ridge = ridge_test_rss\n",
    "        min_test_error_lasso = lasso_test_rss\n",
    "        optimal_ridge_alpha = a\n",
    "        optimal_lasso_alpha = a\n",
    "    if min_test_error_ridge > ridge_test_rss:\n",
    "        min_test_error_ridge = ridge_test_rss\n",
    "        optimal_ridge_alpha = a\n",
    "    if min_test_error_lasso > lasso_test_rss:\n",
    "        min_test_error_lasso = lasso_test_rss\n",
    "        optimal_lasso_alpha = a\n",
    "print('Minimum Ridge Test RSS: {}, Best alpha: {}'.format(min_test_error_ridge, optimal_ridge_alpha))\n",
    "print('Minimum Lasso Test RSS: {}, Best alpha: {}'.format(min_test_error_lasso, optimal_lasso_alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
